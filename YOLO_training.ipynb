{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Training Notebook\n",
    "Authors: Cait Newport & Rachel Parkinson\n",
    "Date: 2025-01-31\n",
    "\n",
    "This is a notebook to help with YOLO training.\n",
    "It assumes you have a dataset in YOLO format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "This has been tested on a Mac (with M3 chip) and Windows (with CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN COMMANDS IN THIS CELL FROM THE TERMINAL or with ! in front of the command in a cell\n",
    "\n",
    "# You will get error messages if you try to install torch with newer python versions. Stick with Python 3.11\n",
    "\n",
    "# For Mac:\n",
    "# brew install python@3.11\n",
    "\n",
    "# For Windows:\n",
    "# Download Python 3.11 from https://www.python.org/downloads/\n",
    "# Make sure to check \"Add Python to PATH\" during installation\n",
    "\n",
    "# Create and activate a Python virtual environment\n",
    "# For Mac:\n",
    "# python3.11 -m venv yolo_training_enviro\n",
    "# source yolo_training_enviro/bin/activate\n",
    "\n",
    "# For Windows:\n",
    "# python -m venv yolo_training_enviro\n",
    "# yolo_training_enviro\\Scripts\\activate\n",
    "\n",
    "# Install ipykernel if not already installed\n",
    "!pip install ipykernel\n",
    "\n",
    "# Register the kernel with Jupyter\n",
    "!python -m ipykernel install --user --name=yolo_training_enviro --display-name=\"YOLO Training (Python 3.11)\"\n",
    "\n",
    "# In later stages you may get errors about 'import'. You may need to change your kernel to the one you just created.\n",
    "# You can do this by clicking on the kernel in the top right of the notebook and selecting the kernel you want.\n",
    "# Choose \"YOLO Training (Python 3.11)\" which you just made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Verify the kernel is correct by running this cell:\n",
    "import sys\n",
    "print(sys.executable)  # This will show which Python interpreter you're using\n",
    "# It should now show a path that includes your virtual environment (yolo_training_enviro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch (run the correct command in the terminal)\n",
    "\n",
    "# For Mac with M-series chip (M1/M2/M3):\n",
    "# pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "\n",
    "# For Mac with Intel chip:\n",
    "# pip3 install torch torchvision torchaudio\n",
    "\n",
    "# For Windows:\n",
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch can be optimized for a MAC M3 chip. To check if it is, run this cell (Mac only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check PyTorch device configuration\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# For Mac:\n",
    "print(f\"MPS (Metal) available: {torch.backends.mps.is_available()}\")\n",
    "print(f\"Current device: {torch.device('mps' if torch.backends.mps.is_available() else 'cpu')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch can be optimized for a Windows GPU. To check if it is, run this cell (Windows only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cpu\n",
      "CUDA available: False\n",
      "No CUDA GPU available, using CPU\n",
      "Current device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check PyTorch device configuration\n",
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# For Windows with GPU:\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Current device: {torch.device('cuda')}\")\n",
    "else:\n",
    "    print(\"No CUDA GPU available, using CPU\")\n",
    "    print(f\"Current device: {torch.device('cpu')}\")\n",
    "\n",
    "# If you see that CUDA is not available on a Windows machine with a GPU, you might need to:\n",
    "# 1. Install the NVIDIA CUDA Toolkit\n",
    "# 2. Install the correct PyTorch version with CUDA support (using the command from the previous response)\n",
    "# 3. Make sure you have updated NVIDIA drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You can still train YOLO on a CPU, but it will be slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ultralytics which has the YOLO library.\n",
    "\n",
    "# pip install ultralytics # (run this in the terminal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "You will need to have a dataset in YOLO format.\n",
    "\n",
    "You can generate a dataset of labelled images using a tool like Label Studio: https://labelstud.io/\n",
    "\n",
    "The folder structure should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset/\n",
    "  ├── images/\n",
    "  │   ├── image1.jpg\n",
    "  │   └── image2.jpg\n",
    "  ├── labels/\n",
    "  │   ├── image1.txt\n",
    "  │   └── image2.txt\n",
    "  └── classes.txt  # or data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A text file would have the classes listed in order. For example:\n",
    "\n",
    "\n",
    "  triggerfish\n",
    "\n",
    "  shark\n",
    "\n",
    "  octopus\n",
    "\n",
    "A data.yaml file would have the classes listed in order. For example:\n",
    "\n",
    "\n",
    "names:\n",
    "\n",
    "  0: triggerfish\n",
    "\n",
    "  1: shark\n",
    "\n",
    "  2: octopus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see some of your images with annotations:\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Update these paths to match your directory structure\n",
    "IMAGE_DIR = \"./dataset/images\"\n",
    "LABEL_DIR = \"./dataset/labels\"\n",
    "class_names = [\"bee\", \"feeder\"]  # Replace with your classes\n",
    "\n",
    "# Choose a specific image to visualize\n",
    "image_name = \"0de83328-img10071.png\"  # Replace with your image name\n",
    "label_name = image_name.replace('.png', '.txt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "image_path = os.path.join(IMAGE_DIR, image_name)\n",
    "img = cv2.imread(image_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Show original image\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Original Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your labels data will either be formatted using class_id, x_center, y_center, width, height or using 4 corner points (x,y pairs) for rotated bounding boxes. \n",
    "\n",
    "This will depend how you have labelled your images and how you exported the data from your labelling tool. \n",
    "\n",
    "Either format works fine for YOLO automatically, however the subsequent code will need to be adjusted to match the format of your labels.\n",
    "\n",
    "For the format using class_id, x_center, y_center, width, height:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read annotations\n",
    "label_path = os.path.join(LABEL_DIR, label_name)\n",
    "boxes = []\n",
    "\n",
    "with open(label_path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "        boxes.append([int(class_id), x_center, y_center, width, height])\n",
    "\n",
    "# Convert and draw boxes\n",
    "img_height, img_width = img.shape[:2]\n",
    "img_with_boxes = img.copy()\n",
    "\n",
    "for box in boxes:\n",
    "    class_id, x_center, y_center, width, height = box\n",
    "    \n",
    "    # Convert normalized coordinates to pixel coordinates\n",
    "    x = int((x_center - width/2) * img_width)\n",
    "    y = int((y_center - height/2) * img_height)\n",
    "    w = int(width * img_width)\n",
    "    h = int(height * img_height)\n",
    "    \n",
    "    # Draw rectangle\n",
    "    cv2.rectangle(img_with_boxes, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Add label\n",
    "    label = class_names[int(class_id)] if class_names else str(int(class_id))\n",
    "    cv2.putText(img_with_boxes, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display image with boxes\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(img_with_boxes)\n",
    "plt.axis('off')\n",
    "plt.title('Image with YOLO Annotations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, for rotated bounding boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read annotations\n",
    "label_path = os.path.join(LABEL_DIR, label_name)\n",
    "boxes = []\n",
    "\n",
    "with open(label_path, 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        values = line.strip().split()\n",
    "        class_id = int(float(values[0]))\n",
    "        # Extract 4 corner points (x,y pairs)\n",
    "        points = np.array([\n",
    "            [float(values[1]), float(values[2])],  # top-left\n",
    "            [float(values[3]), float(values[4])],  # top-right\n",
    "            [float(values[5]), float(values[6])],  # bottom-right\n",
    "            [float(values[7]), float(values[8])]   # bottom-left\n",
    "        ])\n",
    "        boxes.append([class_id, points])\n",
    "\n",
    "# Convert and draw boxes\n",
    "img_height, img_width = img.shape[:2]\n",
    "img_with_boxes = img.copy()\n",
    "\n",
    "for box in boxes:\n",
    "    class_id, points = box\n",
    "    \n",
    "    # Convert normalized coordinates to pixel coordinates\n",
    "    points[:, 0] *= img_width   # x coordinates\n",
    "    points[:, 1] *= img_height  # y coordinates\n",
    "    points = points.astype(np.int32)\n",
    "    \n",
    "    # Draw the rotated box\n",
    "    cv2.polylines(img_with_boxes, [points], True, (0, 255, 0), 2)\n",
    "    \n",
    "    # Add label at the top-left corner\n",
    "    label = class_names[class_id] if class_names else str(class_id)\n",
    "    cv2.putText(img_with_boxes, label, \n",
    "                (points[0][0], points[0][1] - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "# Display image with boxes\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(img_with_boxes)\n",
    "plt.axis('off')\n",
    "plt.title('Image with Rotated Annotations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To View multiple samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of image files\n",
    "image_files = [f for f in os.listdir(IMAGE_DIR) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "# Select 3 random samples\n",
    "num_samples = 3\n",
    "samples = np.random.choice(image_files, num_samples)\n",
    "\n",
    "# Process each sample\n",
    "for image_name in samples:\n",
    "    # Get corresponding label file name\n",
    "    label_name = os.path.splitext(image_name)[0] + '.txt'\n",
    "    \n",
    "    # Read image\n",
    "    image_path = os.path.join(IMAGE_DIR, image_name)\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Could not load image from {image_path}\")\n",
    "        continue\n",
    "        \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Read annotations\n",
    "    label_path = os.path.join(LABEL_DIR, label_name)\n",
    "    boxes = []  # Reset boxes for each new image\n",
    "\n",
    "    try:\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                values = line.strip().split()\n",
    "                class_id = int(float(values[0]))\n",
    "                # Extract the 4 corner points (x,y pairs)\n",
    "                points = np.array([\n",
    "                    [float(values[1]), float(values[2])],  # first point\n",
    "                    [float(values[3]), float(values[4])],  # second point\n",
    "                    [float(values[5]), float(values[6])],  # third point\n",
    "                    [float(values[7]), float(values[8])]   # fourth point\n",
    "                ])\n",
    "                boxes.append([class_id, points])\n",
    "\n",
    "        # Draw boxes\n",
    "        img_height, img_width = img.shape[:2]\n",
    "\n",
    "        for box in boxes:\n",
    "            class_id, points = box\n",
    "            \n",
    "            # Convert normalized coordinates to pixel coordinates\n",
    "            points_px = points.copy()\n",
    "            points_px[:, 0] *= img_width   # scale x coordinates\n",
    "            points_px[:, 1] *= img_height  # scale y coordinates\n",
    "            points_px = points_px.astype(np.int32)\n",
    "            \n",
    "            # Draw the rotated box\n",
    "            cv2.polylines(img, [points_px], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "            \n",
    "            # Add label at the top-left corner of the box\n",
    "            label = class_names[int(class_id)] if class_names else str(int(class_id))\n",
    "            cv2.putText(img, label, \n",
    "                        (points_px[0][0], points_px[0][1] - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Display\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Sample: {image_name} - {len(boxes)} boxes')\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: No label file found for {image_name}\")\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {label_path}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training a YOLO detector, we split our dataset into training and validation sets for a few key reasons:\n",
    "\n",
    "The training set is used to actually teach the model, updating its weights and biases as it learns to detect objects. The validation set, on the other hand, serves as an independent test to check if the model is actually learning to generalize rather than just memorizing the training data.\n",
    "\n",
    "This separation helps us detect overfitting - a situation where the model performs really well on the training data but fails on new, unseen images. If we see the model's performance improving on the training set but getting worse on the validation set, that's a clear sign of overfitting.\n",
    "Think of it like studying for an exam - you want to learn the concepts (training) but also check your understanding on practice problems you haven't seen before (validation) to make sure you truly understand the material rather than just memorizing specific examples.\n",
    "This split also helps with tuning hyperparameters like learning rate or batch size, as we can adjust these based on validation performance without contaminating our final test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def split_dataset(train_ratio=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Split dataset into training and validation sets with YOLO folder structure.\n",
    "    \n",
    "    Args:\n",
    "        train_ratio (float): Ratio of training data (default: 0.8)\n",
    "        seed (int): Random seed for reproducibility (default: 42)\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Setup paths\n",
    "    dataset_path = Path('dataset')\n",
    "    \n",
    "    # Create YOLO-standard directory structure\n",
    "    train_img_dir = dataset_path / 'train' / 'images'\n",
    "    train_label_dir = dataset_path / 'train' / 'labels'\n",
    "    val_img_dir = dataset_path / 'val' / 'images'\n",
    "    val_label_dir = dataset_path / 'val' / 'labels'\n",
    "    \n",
    "    # Create directories\n",
    "    for dir_path in [train_img_dir, train_label_dir, val_img_dir, val_label_dir]:\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Get list of image files\n",
    "    image_files = [f for f in os.listdir(dataset_path / 'images') \n",
    "                  if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    # Randomly split indices\n",
    "    num_files = len(image_files)\n",
    "    num_train = int(num_files * train_ratio)\n",
    "    indices = np.random.permutation(num_files)\n",
    "    train_indices = indices[:num_train]\n",
    "    val_indices = indices[num_train:]\n",
    "    \n",
    "    print(\"Splitting dataset...\")\n",
    "    print(f\"Total images: {num_files}\")\n",
    "    print(f\"Training images: {len(train_indices)}\")\n",
    "    print(f\"Validation images: {len(val_indices)}\")\n",
    "    \n",
    "    # Copy files to train/val directories\n",
    "    for idx in train_indices:\n",
    "        img_file = image_files[idx]\n",
    "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "        \n",
    "        # Copy image\n",
    "        shutil.copy2(\n",
    "            dataset_path / 'images' / img_file,\n",
    "            train_img_dir / img_file\n",
    "        )\n",
    "        \n",
    "        # Copy label if it exists\n",
    "        if os.path.exists(dataset_path / 'labels' / label_file):\n",
    "            shutil.copy2(\n",
    "                dataset_path / 'labels' / label_file,\n",
    "                train_label_dir / label_file\n",
    "            )\n",
    "    \n",
    "    for idx in val_indices:\n",
    "        img_file = image_files[idx]\n",
    "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "        \n",
    "        # Copy image\n",
    "        shutil.copy2(\n",
    "            dataset_path / 'images' / img_file,\n",
    "            val_img_dir / img_file\n",
    "        )\n",
    "        \n",
    "        # Copy label if it exists\n",
    "        if os.path.exists(dataset_path / 'labels' / label_file):\n",
    "            shutil.copy2(\n",
    "                dataset_path / 'labels' / label_file,\n",
    "                val_label_dir / label_file\n",
    "            )\n",
    "    \n",
    "    print(\"\\nDataset split complete!\")\n",
    "    print(f\"Training images: {len(list(train_img_dir.glob('*')))} files\")\n",
    "    print(f\"Training labels: {len(list(train_label_dir.glob('*')))} files\")\n",
    "    print(f\"Validation images: {len(list(val_img_dir.glob('*')))} files\")\n",
    "    print(f\"Validation labels: {len(list(val_label_dir.glob('*')))} files\")\n",
    "\n",
    "# Run the split\n",
    "if __name__ == \"__main__\":\n",
    "    split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image size\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def check_image_sizes(image_dir):\n",
    "    widths = []\n",
    "    heights = []\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    print(f\"\\nChecking {len(image_files)} images in {image_dir}\")\n",
    "    \n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        with Image.open(img_path) as img:\n",
    "            width, height = img.size\n",
    "            widths.append(width)\n",
    "            heights.append(height)\n",
    "    \n",
    "    print(f\"Width  - Min: {min(widths)}, Max: {max(widths)}, Mean: {np.mean(widths):.0f}\")\n",
    "    print(f\"Height - Min: {min(heights)}, Max: {max(heights)}, Mean: {np.mean(heights):.0f}\")\n",
    "    \n",
    "    # Show a few example sizes\n",
    "    unique_sizes = set(zip(widths, heights))\n",
    "    print(f\"\\nUnique image sizes found: {len(unique_sizes)}\")\n",
    "    for size in list(unique_sizes)[:5]:\n",
    "        print(f\"- {size[0]} x {size[1]}\")\n",
    "\n",
    "# Check both train and val directories\n",
    "check_image_sizes(\"dataset/images_train\")\n",
    "check_image_sizes(\"dataset/images_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def print_directory_structure():\n",
    "    base_dir = Path('dataset')\n",
    "    print(\"\\nChecking directory structure:\")\n",
    "    print(f\"\\nContents of {base_dir}:\")\n",
    "    for item in base_dir.iterdir():\n",
    "        print(f\"- {item.name}\")\n",
    "    \n",
    "    # Check labels directories\n",
    "    labels_train = base_dir / 'labels_train'\n",
    "    labels_val = base_dir / 'labels_val'\n",
    "    \n",
    "    if labels_train.exists():\n",
    "        print(f\"\\nContents of {labels_train}:\")\n",
    "        files = list(labels_train.glob('*.txt'))\n",
    "        print(f\"Found {len(files)} .txt files\")\n",
    "        if files:\n",
    "            print(\"First 5 label files:\")\n",
    "            for f in files[:5]:\n",
    "                print(f\"- {f.name}\")\n",
    "    else:\n",
    "        print(f\"\\n{labels_train} directory not found!\")\n",
    "        \n",
    "    if labels_val.exists():\n",
    "        print(f\"\\nContents of {labels_val}:\")\n",
    "        files = list(labels_val.glob('*.txt'))\n",
    "        print(f\"Found {len(files)} .txt files\")\n",
    "        if files:\n",
    "            print(\"First 5 label files:\")\n",
    "            for f in files[:5]:\n",
    "                print(f\"- {f.name}\")\n",
    "    else:\n",
    "        print(f\"\\n{labels_val} directory not found!\")\n",
    "\n",
    "print_directory_structure()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_training_enviro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
